---
title: MySQL强一致性方案PXC
subtitle: docker实战
date: 2018-06-02
tags: ["运维", "mysql"]
draft: false
---

之前工作的公司，MySQL集群架构使用的是Replication，也就是自带的主从同步来保证数据备份。之后推出的架构中有一种双机高可用方案，宕掉一台机器后依然保证服务可用，数据库使用主主完成。

但是主主本身有一定缺陷，比如其中有一台MySQL因网络问题主从连接故障后，两者的数据库就会不同步，由于双主两台机器都在做写入操作，造成数据混乱引出灾难性的后果，后期恢复也很难实施。

<!--more-->

PXC大致原理为：当有写入修改操作时，将该操作在集群内所有机器上都执行一遍，只有所有机器都确认完成后，这条操作才算成功。大致可以总结为以下几个特点：

- 强一致性，要么全成功，要么全失败，保证每个节点数据一致
- 数据一致，意味着全部节点可读可写，常规读写分离变负载均衡
- 无同步延迟
- 因为所有节点都要执行一次写操作，所以速度慢于主从方案
- 最后一个节点写入后才算成功写入，因此写入速度取决于集群内最慢的那台机器

借用下网上的时序图：
![](https://images.moonlightming.com/images/20180601071932.png)
当集群中任意节点执行写操作时，请求提交给PXC，PXC负责将写操作在其他节点也执行一遍，当所有节点执行成功时，才会正式写入。

综上所述，PXC性能稍差但数据安全等级极高，适合对数据安全有要求的架构。

## PXC集群部署
之前公司一直准备服务容器化，我负责落地方案，因此这次使用docker进行部署演示。当然，实际生产环境中使用有状态程序是需要诸多考虑的，尤其是数据库、缓存一类的场景下。打个比方，容器集群内有一个容器挂掉了，__在没有存储卷绑定的情况下__，swarm会新开一个容器，此时新容器数据为空，其他节点就会向这个节点进行数据同步，这会极大地拖慢集群内速度。尤其是这种速度取决于最慢节点的架构。

首先需要下载集群搭建所需的镜像：
```shell
docker pull percona/percona-xtradb-cluster
```

docker数据库集群有几个特点需要说明：

- 每个容器必须各自使用独立存储，不允许容器共享
- 由于数据一致性，不使用Service横向拓展
- PXC集群一般先建立一个节点做集群初始化主节点。只有在该节点启动完毕后，其他节点在加入集群。

一个三节点PXC集群Docker-compose配置示例：
```yaml
version: "3.4"

networks:
  pxc:
    driver: overlay

volumes:
  v1:
  v2:
  v3:

services:
  mysql-pxc1:
    image: percona/percona-xtradb-cluster
    deploy:
      mode: global
    environment:
      - MYSQL_ROOT_PASSWORD=abc123
      - CLUSTER_NAME=PXC
      - XTRABACKUP_PASSWORD=abc123
    volumes:
      - v1:/var/lib/mysql
    networks:
      - pxc
    ports:
      - 3306:3306

  mysql-pxc2:
    image: percona/percona-xtradb-cluster
    deploy:
      mode: global
    environment:
      - MYSQL_ROOT_PASSWORD=abc123
      - CLUSTER_NAME=PXC
      - XTRABACKUP_PASSWORD=abc123
      - CLUSTER_JOIN=mysql-pxc1
    volumes:
      - v2:/var/lib/mysql
    networks:
      - pxc
    ports:
      - 3307:3306
    depends_on:
      - mysql-pxc1

  mysql-pxc3:
    image: percona/percona-xtradb-cluster
    deploy:
      mode: global
    environment:
      - MYSQL_ROOT_PASSWORD=abc123
      - CLUSTER_NAME=PXC
      - XTRABACKUP_PASSWORD=abc123
      - CLUSTER_JOIN=mysql-pxc1
    volumes:
      - v3:/var/lib/mysql
    networks:
      - pxc
    ports:
      - 3308:3306
    depends_on:
      - mysql-pxc1
```

使用以下命令在docker swarm上运行集群：
```
docker stack deploy -c pxc.yaml pxc
```

从以上配置可以看出，每个服务当作是一个节点，多少个服务节点创建多少个volume，其中mysql-pxc1作为初始化主节点，另外两节点使用depends_on关键字让1节点优先运行。即使开头运行失败，docker自我恢复机制也会让另外两节点重新加入。需要注意的是在每个容器写入的环境变量中，1节点初始化了CLUSTER_NAME，另外两节点使用CLUSTER_JOIN去加入1节点创建的PXC集群。三个节点分别将自身3306端口映射至宿主机的3306、3307、3308。

## 验证
当集群启动完毕后，已经可以尝试集群读写，此时三个MySQL节点都是可读可写的。并且保持数据一致性。可以使用远程连接工具测试，随便在一个节点执行SQL语句：
```sql
create database a;
```

现在每个节点都有一个名为a的库。

![](https://images.moonlightming.com/images/20180602014036.png)

## 负载均衡
集群可用后，由于使用容器——服务对应的方式部署，Swarm自带的Service负载均衡无法使用，因此需要部署HaProxy容器进行负载均衡，使每个节点都承担读写任务。

先下载HaProxy镜像：
```shell
docker pull haproxy
```

编写haprox配置，在标准配置中添加如下内容：
```shell
listen proxy-mysql
       bind 0.0.0.0:3306
       # 网络协议
       mode tcp
       # 负载均衡算法（轮询）
       balance roundrobin
       # 日志格式
       option tcplog
       # 心跳检测，需要在mysql中创建一个没有权限的haproxy用户，密码为空。Haproxy使用这个账户对MySQL进行心跳检测
       option mysql-check user haproxy
       server MYSQL_1 mysql-pxc1:3306 check weight 1 maxconn 2000
       server MYSQL_2 mysql-pxc2:3306 check weight 1 maxconn 2000
       server MYSQL_3 mysql-pxc3:3306 check weight 1 maxconn 2000
       # 使用keepalive检测死链
       option tcpka
```

在之前的PXC集群Docker-compose配置中添加如下内容：
```yaml
    haproxy:
        image: haproxy
        ports:
          - 4001:8888
          - 4002:3306
        volumes:
          - ./haproxy.cfg:/usr/local/etc/haproxy/haproxy.cfg:ro
        networks:
          - pxc
        entrypoint:
          - haproxy
          - '-f'
          - /usr/local/etc/haproxy/haproxy.cfg
```
由于有haprox负责监听宿主机3306端口负载均衡，因此之前docker-compose配置中每个容器对外暴露的3306端口可以取消，生产环境中也不允许对外暴露。

重新启动一下：
```
docker stack deploy -c pxc.yaml pxc
```

4001端口对外提供了HaProxy的web界面，4002对外提供PXC负载均衡。
完毕！
